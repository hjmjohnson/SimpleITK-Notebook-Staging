{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">It's About Time</h1>\n",
    "\n",
    "When developing a registration algorithm or when selecting parameter value settings for an existing algorithm our choices are dictated by two, often opposing, constraints:\n",
    "<ul>\n",
    "<li>Required accuracy.</li>\n",
    "<li>Alloted time.</li>\n",
    "</ul>\n",
    "\n",
    "As the goal of registration is to align multiple data elements into the same coordinate system, it is only natural that the primary focus is on accuracy. In most cases the reported accuracy is obtained without constraining the algorithm's execution time. A complete evaluation should also provide the corresponding running times. This approach is appropriate for longitudinal studies where we have the benefit of loose constraints on time. In this setting a registration taking an hour is perfectly acceptable. At the other end of the spectrum we have intra-operative registration. In this setting, registration is expected to complete within seconds or minutes. The  underlying reasons for tight timining constraints have to do with the detrimental effects of prolonged anesthesia and with the increased costs of operating room time. At the same time, simply completing on time without sufficient accuracy is also unacceptable.  \n",
    "\n",
    "This notebook illustrates a straightforward approach for offsetting the computational complexity of registration via preprocessing and increased memory usage. \n",
    "\n",
    "The computational cost of registration is primarily associated with interpolation, required for evaluating the similarity metric. Ideally we would like to use the fastest possible interpolation method, nearest neighbor. Unfortunatly, nearest neighbor interpolation most often yields sub-optimal results. A straightforward solution is to pre-operativly create a super-sampled version of the moving-image using higher order interpolation*. We then perform registration between the fixed-image and super-sampled moving-image, using nearest neighbor interoplation.\n",
    "\n",
    "Tallying up time and memory usage we see that:\n",
    "\n",
    "<table>\n",
    "  <tr><td></td> <td><b>time</b></td><td><b>memory</b></td></tr>\n",
    "  <tr><td><b>pre-operative</b></td> <td>increase</td><td>increase</td></tr>\n",
    "  <tr><td><b>intra-operative</b></td> <td>decrease</td><td>increase</td></tr>\n",
    "</table><br><br>  \n",
    "\n",
    "\n",
    "<font size=\"-1\">*A better approach is to use single image super resolution techniques such as the one desrcibed in A. Rueda, N. Malpica, E. Romero,\"Single-image super-resolution of brain MR images using overcomplete dictionaries\", <i>Med Image Anal.</i>, 17(1):113-132, 2013.</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "#utility method that either downloads data from the MIDAS repository or\n",
    "#if already downloaded returns the file name for reading from disk (cached data)\n",
    "from downloaddata import fetch_midas_data as fdata\n",
    "\n",
    "#always write output to a separate directory, we don't want to polute the source directory \n",
    "import os\n",
    "OUTPUT_DIR = 'Output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Utility functions\n",
    "\n",
    "A number of utility callback functions for loading the RIRE points, estimating the transformation and generating\n",
    "our own reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "def load_RIRE_points(file_name):\n",
    "    '''\n",
    "    Load the point sets defining the ground truth transformations for the RIRE training dataset.\n",
    "\n",
    "    Args: \n",
    "        file_name (str): RIRE ground truth file name. File format is specific to the RIRE training data, with\n",
    "                         the actual data expectd to be in lines 15-23.\n",
    "    Returns:\n",
    "    Two lists of tuples representing the points in the \"left\" and \"right\" coordinate systems.\n",
    "    '''\n",
    "    fp = open(file_name, 'r')\n",
    "    lines = fp.readlines()\n",
    "    l = []\n",
    "    r = []\n",
    "    \n",
    "    #fiducial information is in lines 15-22, starting with the second entry\n",
    "    for line in lines[15:23]:\n",
    "        coordinates = line.split()\n",
    "        l.append((float(coordinates[1]), float(coordinates[2]), float(coordinates[3])))\n",
    "        r.append((float(coordinates[4]), float(coordinates[5]), float(coordinates[6])))\n",
    "    return (l, r)\n",
    "\n",
    "\n",
    "def absolute_orientation_m(points_in_left, points_in_right):\n",
    "    '''\n",
    "    Absolute orientation using a matrix to represent the rotation. Solution is due to\n",
    "    S. Umeyama, \"Least-Squares Estimation of Transformation Parameters \n",
    "    Between Two Point Patterns\", IEEE Trans. Pattern Anal. Machine Intell., vol. 13(4): 376-380.\n",
    "    \n",
    "    This is a refinement of the method proposed by Arun, Huang and Blostein, ensuring that the \n",
    "    rotation matrix is indeed a rotation and not a reflection. \n",
    "    \n",
    "    Args:\n",
    "        points_in_left (list(tuple)): Set of points corresponding to points_in_right in a different coordinate system.\n",
    "        points_in_right (list(tuple)): Set of points corresponding to points_in_left in a different coordinate system.\n",
    "        \n",
    "    Returns:\n",
    "        R,t (numpy.ndarray, numpy.array): Rigid transformation that maps points_in_left onto points_in_right.\n",
    "                                          R*points_in_left + t = points_in_right\n",
    "    '''\n",
    "    num_points = len(points_in_left)\n",
    "    dim_points = len(points_in_left[0])\n",
    "    \n",
    "    #cursory check that the number of points is sufficient\n",
    "    if num_points<dim_points:      \n",
    "        raise ValueError('Number of points must be greater/equal {0}.'.format(dim_points))\n",
    "\n",
    "    #construct matrices out of the two point sets for easy manipulation\n",
    "    left_mat = np.array(points_in_left).T\n",
    "    right_mat = np.array(points_in_right).T\n",
    "     \n",
    "    #center both data sets on the mean\n",
    "    left_mean = left_mat.mean(1)\n",
    "    right_mean = right_mat.mean(1)\n",
    "    left_M = left_mat - np.tile(left_mean, (num_points, 1)).T     \n",
    "    right_M = right_mat - np.tile(right_mean, (num_points, 1)).T     \n",
    "    \n",
    "    M = left_M.dot(right_M.T)               \n",
    "    U,S,Vt = linalg.svd(M)\n",
    "    V=Vt.T\n",
    "    \n",
    "    #V * diag(1,1,det(U*V)) * U' - diagonal matrix ensures that we have a rotation and not a reflection\n",
    "    R = V.dot(np.diag((1,1,linalg.det(U.dot(V))))).dot(U.T) \n",
    "    t = right_mean - R.dot(left_mean) \n",
    "    return R,t\n",
    "\n",
    "\n",
    "def generate_random_pointset(image, num_points):\n",
    "    '''\n",
    "    Generate a random set (uniform sample) of points in the given image's domain.\n",
    "    \n",
    "    Args:\n",
    "        image (SimpleITK.Image): Domain in which points are created.\n",
    "        num_points (int): Number of points to generate.\n",
    "        \n",
    "    Returns:\n",
    "        A list of points (tuples).\n",
    "    '''\n",
    "    \n",
    "    #continous random uniform point indexes inside the image bounds\n",
    "    point_indexes = np.multiply(np.tile(image.GetSize(), (num_points, 1)), np.random.random((num_points, image.GetDimension())))\n",
    "    pointset_list = point_indexes.tolist()\n",
    "    \n",
    "    #get a list of physical points corresponding to the indexes\n",
    "    return [image.TransformContinuousIndexToPhysicalPoint(point_index) for point_index in pointset_list]\n",
    "\n",
    "\n",
    "def registration_errors(tx, reference_fixed_point_list, reference_moving_point_list):\n",
    "  '''\n",
    "  Distances between points transformed by the given transformation and their\n",
    "  location in another coordinate system. When the points are only used to evaluate\n",
    "  registration accuracy (not used in the registration) this is the target registration\n",
    "  error (TRE).\n",
    "  \n",
    "  Args:\n",
    "      tx (SimpleITK.Transform): The transform we want to evaluate.\n",
    "      reference_fixed_point_list (list(tuple-like)): Points in fixed image cooredinate system.\n",
    "      reference_moving_point_list (list(tuple-like)): Points in moving image cooredinate system.\n",
    "\n",
    "  Returns:\n",
    "   (mean, std, min, max, errors) (float, float, float, float, [float]): TRE statistics and original TREs.\n",
    "  '''\n",
    "  errors = [linalg.norm(np.array(tx.TransformPoint(p_fixed)) -  np.array(p_moving))\n",
    "            for p_fixed,p_moving in zip(reference_fixed_point_list, reference_moving_point_list)]\n",
    "  return (np.mean(errors), np.std(errors), np.min(errors), np.max(errors), errors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of utility callback functions for image display and for ploting the similarity metric and target \n",
    "registration errors during registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.html.widgets import interact, fixed\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#callback invoked by the interact ipython method for scrolling through the image stacks of\n",
    "#the two images (moving and fixed)\n",
    "def display_images(fixed_image_z, moving_image_z, resampled_moving_image_z, fixed_npa, moving_npa, resmapled_moving_npa):\n",
    "    #create a figure with two subplots and the specified size\n",
    "    plt.subplots(1,3,figsize=(10,8))\n",
    "    \n",
    "    #draw the fixed image in the first subplot\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(fixed_npa[fixed_image_z,:,:],cmap=plt.cm.Greys_r);\n",
    "    plt.title('fixed image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #draw the moving image in the second subplot\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(moving_npa[moving_image_z,:,:],cmap=plt.cm.Greys_r);\n",
    "    plt.title('moving image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    #draw the moving resampled image in the third subplot\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(resmapled_moving_npa[resampled_moving_image_z,:,:],cmap=plt.cm.Greys_r);\n",
    "    plt.title('resampled moving image')\n",
    "    plt.axis('off')\n",
    "\n",
    "        \n",
    "#callback invoked by the ipython interact method for scrolling and modifying the alpha blending\n",
    "#of an image stack of two images that occupy the same physical space. \n",
    "def display_images_with_alpha(image_z, alpha, fixed, moving):\n",
    "    img = (1.0 - alpha)*fixed[:,:,image_z] + alpha*moving[:,:,image_z] \n",
    "    plt.imshow(sitk.GetArrayFromImage(img),cmap=plt.cm.Greys_r);\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "#callback invoked when the StartEvent happens, sets up our new data\n",
    "def start_plot():\n",
    "    global metric_values, multires_iterations, reference_mean_values\n",
    "    global reference_min_values, reference_max_values\n",
    "    \n",
    "    metric_values = []\n",
    "    multires_iterations = []\n",
    "    reference_mean_values = []\n",
    "    reference_min_values = []\n",
    "    reference_max_values = []\n",
    "\n",
    "#callback invoked when the EndEvent happens, do cleanup of data and figure\n",
    "def end_plot():\n",
    "    global metric_values, multires_iterations, reference_mean_values\n",
    "    global reference_min_values, reference_max_values\n",
    "    \n",
    "    del metric_values\n",
    "    del multires_iterations\n",
    "    del reference_mean_values\n",
    "    del reference_min_values\n",
    "    del reference_max_values\n",
    "    \n",
    "    #close figure, we don't want to get a duplicate of the plot latter on\n",
    "    plt.close()\n",
    "\n",
    "#callback invoked when the IterationEvent happens, update our data and display new figure    \n",
    "def plot_values(registration_method, fixed_points, moving_points):\n",
    "    global metric_values, multires_iterations, reference_mean_values\n",
    "    global reference_min_values, reference_max_values\n",
    "    \n",
    "    metric_values.append(registration_method.GetMetricValue())\n",
    "    \n",
    "    #compute and store TRE statistics (mean, min, max)\n",
    "    current_transform = sitk.Transform(registration_method.GetInitialTransform())\n",
    "    current_transform.SetParameters(registration_method.GetOptimizerPosition())\n",
    "    current_transform.AddTransform(registration_method.GetMovingInitialTransform())\n",
    "    current_transform.AddTransform(registration_method.GetFixedInitialTransform().GetInverse())\n",
    "    mean_error, _, min_error, max_error, _ = registration_errors(current_transform, fixed_points, moving_points)\n",
    "    reference_mean_values.append(mean_error)\n",
    "    reference_min_values.append(min_error)\n",
    "    reference_max_values.append(max_error)\n",
    "                                       \n",
    "    #clear the output area (wait=True, to reduce flickering), and plot current data\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    #plot the similarity metric values\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(metric_values, 'r')\n",
    "    plt.plot(multires_iterations, [metric_values[index] for index in multires_iterations], 'b*')\n",
    "    plt.xlabel('Iteration Number',fontsize=12)\n",
    "    plt.ylabel('Metric Value',fontsize=12)\n",
    "    \n",
    "    #plot the TRE mean value and the [min-max] range\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(reference_mean_values, color='black', label='mean')\n",
    "    plt.fill_between(range(len(reference_mean_values)), reference_min_values, reference_max_values, \n",
    "                     facecolor='red', alpha=0.5)\n",
    "    plt.xlabel('Iteration Number', fontsize=12)\n",
    "    plt.ylabel('TRE [mm]', fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "    #adjust the spacing between subplots so that the axis labels don't overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the \n",
    "#metric_values list. We assume this event happens before the first IterationEvent on the next resolution.\n",
    "def update_multires_iterations():\n",
    "    global metric_values, multires_iterations\n",
    "    multires_iterations.append(len(metric_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "###Read Images\n",
    "\n",
    "We first read the images, casting the pixel type to that required for registration (Float32 or Float64) and look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_image =  sitk.ReadImage(fdata(\"training_001_ct.mha\"), sitk.sitkFloat32)\n",
    "moving_image = sitk.ReadImage(fdata(\"training_001_mr_T1.mha\"), sitk.sitkFloat32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample moving image\n",
    "\n",
    "We now resample our moving image to a very fine spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#isotropic voxels with 0.5mm spacing\n",
    "voxel_edge_sizes = [0.5]*moving_image.GetDimension()\n",
    "\n",
    "#create resampled image\n",
    "original_size = moving_image.GetSize()\n",
    "original_spacing = moving_image.GetSpacing()\n",
    "\n",
    "resampled_image_size = [int(spacing/voxel_edge_size*size) \n",
    "                        for spacing, size, voxel_edge_size in zip(original_spacing, original_size, voxel_edge_sizes)]  \n",
    "\n",
    "resampled_moving_image = sitk.Image(resampled_image_size, moving_image.GetPixelIDValue())\n",
    "resampled_moving_image.SetSpacing(voxel_edge_sizes)\n",
    "resampled_moving_image.SetOrigin(moving_image.GetOrigin())\n",
    "resampled_moving_image.SetDirection(moving_image.GetDirection())\n",
    "\n",
    "#resample original image using identity transform\n",
    "resample = sitk.ResampleImageFilter()\n",
    "resample.SetReferenceImage(resampled_moving_image)                      \n",
    "resample.SetInterpolator(sitk.sitkBSpline)  \n",
    "resample.SetTransform(sitk.Transform())\n",
    "resampled_moving_image = resample.Execute(moving_image)\n",
    "\n",
    "print('Original image size and spacing: {0} {1}'.format(original_size, original_spacing)) \n",
    "print('Resampled image size and spacing: {0} {1}'.format(resampled_moving_image.GetSize(), \n",
    "                                                         resampled_moving_image.GetSpacing()))\n",
    "print('Memory ratio: 1 : {0}'.format((np.array(resampled_image_size)/np.array(original_size).astype(float)).prod())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option for resampling an image, without any transformation, is to use the ExpandImageFilter or \n",
    "in its functional form SimpleITK::Expand. This filter accepts the interpolation method and an integral expansion factor. This is a bit less flexible than the resample filter as we have less control over the resulting image's spacing. On the other hand this requires less effort from the developer, a single line of code as compared to the cell above:\n",
    "\n",
    "resampled_moving_image = sitk.Expand(moving_image, [2,2,8], sitk.sitkBSpline)\n",
    "\n",
    "What about computational efficiency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually inspect our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interact(display_images, \n",
    "         fixed_image_z=(0,fixed_image.GetSize()[2]-1), \n",
    "         moving_image_z=(0,moving_image.GetSize()[2]-1),\n",
    "         resampled_moving_image_z = (0,resampled_moving_image.GetSize()[2]-1),\n",
    "         fixed_npa = fixed(sitk.GetArrayFromImage(fixed_image)), \n",
    "         moving_npa=fixed(sitk.GetArrayFromImage(moving_image)),\n",
    "         resmapled_moving_npa=fixed(sitk.GetArrayFromImage(resampled_moving_image)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate reference data\n",
    "\n",
    "The RIRE reference, ground truth, data consists of a set of corresponding points in the fixed and moving coordinate systems. These points were obtained from fiducials embedded in the patient's skull and are thus sparse (eight points). We use these to compute the rigid transformation between the two coordinate systems, and then generate a dense reference. This generated reference data is closer to the data you would use for registration evaluation (a. la. the freely available <a href=\"http://www.creatis.insa-lyon.fr/rio/popi-model?action=show&redirect=popi\">Validation Data for Deformable Image Registration of the Lungs</a>).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_fiducial_points, moving_fiducial_points = load_RIRE_points(fdata(\"ct_T1.standard\"))\n",
    "\n",
    "#estimate the reference_transform defined by the RIRE fiducials and check that the FRE makes sense (low) \n",
    "R, t = absolute_orientation_m(fixed_fiducial_points, moving_fiducial_points)\n",
    "reference_transform = sitk.Euler3DTransform()\n",
    "reference_transform.SetMatrix(R.flatten())\n",
    "reference_transform.SetTranslation(t)\n",
    "reference_errors_mean, reference_errors_std, _, reference_errors_max,_ = registration_errors(reference_transform, fixed_fiducial_points, moving_fiducial_points)\n",
    "print('Reference data errors (FRE) in millimeters, mean(std): {:.2f}({:.2f}), max: {:.2f}'.format(reference_errors_mean, reference_errors_std, reference_errors_max))\n",
    "\n",
    "#generate a reference dataset from the reference transformation \n",
    "#(corresponding points in the fixed and moving images)\n",
    "fixed_points = generate_random_pointset(image=fixed_image, num_points=1000)\n",
    "moving_points = [reference_transform.TransformPoint(p) for p in fixed_points]    \n",
    "\n",
    "pre_errors_mean, pre_errors_std, _, pre_errors_max, _ = registration_errors(sitk.Euler3DTransform(), fixed_points, moving_points)\n",
    "print('Initial errors (TRE) in millimeters, mean(std): {:.2f}({:.2f}), max: {:.2f}'.format(pre_errors_mean, pre_errors_std, pre_errors_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Alignment\n",
    "\n",
    "Use the CenteredTransformInitializer to align the centers of the two volumes and set the center of rotation to the center of the fixed image. We then visually inspect the alignment and quantify the error using our reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_transform = sitk.CenteredTransformInitializer(fixed_image, \n",
    "                                                      moving_image, \n",
    "                                                      sitk.Euler3DTransform(), \n",
    "                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "\n",
    "moving_resampled = sitk.Resample(moving_image, fixed_image, initial_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelIDValue())\n",
    "\n",
    "interact(display_images_with_alpha, image_z=(0,fixed_image.GetSize()[2]), alpha=(0.0,1.0,0.05), fixed = fixed(fixed_image), moving=fixed(moving_resampled));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_errors_mean, pre_errors_std, _, pre_errors_max, _ = registration_errors(initial_transform, fixed_points, moving_points)\n",
    "print('Initial errors (TRE) in millimeters, mean(std): {:.2f}({:.2f}), max: {:.2f}'.format(pre_errors_mean, pre_errors_std, pre_errors_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration\n",
    "\n",
    "To illustrate the effect of using the resampled moving-image and interpolator we use the following registration framework instantiation.\n",
    "\n",
    "We instrumented our code with callbacks that provide visual feedback on the progress of registration. In this case, we plot two quantities, the value of the similarity metric and the actual TREs (mean and range). The former is relevant for all registration tasks, the latter is only available if you have a reference data set, which we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def register_images(fixed_image, moving_image, initial_transform, interpolator):\n",
    "\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    \n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.REGULAR)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "    \n",
    "    registration_method.SetInterpolator(interpolator) \n",
    "    \n",
    "    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=1000) \n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift() \n",
    "    \n",
    "    #don't optimize in-place, not nice to change user's input\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "    \n",
    "    #connect callbacks to registration events, allowing us to plot during registration\n",
    "    registration_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "    registration_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "    registration_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_values(registration_method, fixed_points, moving_points))\n",
    "\n",
    "    final_transform = registration_method.Execute(fixed_image, moving_image)\n",
    "    stopping_condition = registration_method.GetOptimizerStopConditionDescription()\n",
    "    return (final_transform, stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ipython allows us to time our code with minimal effort using the <a href=\"http://ipython.org/ipython-doc/stable/interactive/magics.html?highlight=timeit#magic-timeit\">timeit</a> cell magic (Ipython has a set of predefined functions that use a command line syntax, and are referred to as magic functions). \n",
    "\n",
    "We start by running the registration using the original image data an linear interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r1 -n1\n",
    "\n",
    "final_transform, stopping_condition = register_images(fixed_image, moving_image, initial_transform, sitk.sitkLinear)\n",
    "errors_mean, errors_std, _, errors_max, _ = registration_errors(final_transform, fixed_points, moving_points)\n",
    "print('Optimizer\\'s stopping condition, {0}'.format(stopping_condition))\n",
    "print('Errors (TRE) in millimeters, mean(std): {:.2f}({:.2f}), max: {:.2f}'.format(errors_mean, errors_std, errors_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the registration using the resampled image and nearest neighbor interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r1 -n1\n",
    "\n",
    "final_transform, stopping_condition = register_images(fixed_image, resampled_moving_image, \n",
    "                                                      initial_transform, sitk.sitkNearestNeighbor)\n",
    "errors_mean, errors_std, _, errors_max, _ = registration_errors(final_transform, fixed_points, moving_points)\n",
    "print('Optimizer\\'s stopping condition, {0}'.format(stopping_condition))\n",
    "print('Errors (TRE) in millimeters, mean(std): {:.2f}({:.2f}), max: {:.2f}'.format(errors_mean, errors_std, errors_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
