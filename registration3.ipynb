{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to start somewhere : Registration Initialization \n",
    "\n",
    "Initialization is a critical aspect of most registration algorithms, given that most algorithms are formulated as an iterative optimization problem.\n",
    "\n",
    "In many cases we perform initialization in an automatic manner by making assumptions with regard to the contents of the image and the imaging protocol. For instance, if we expect that images were acquired with the patient in the same orientation we can align the geometric centers of the two volumes or the center of mass of the image contents if the anatomy is not centered in the image (this is what we previously did in [this example](registration1.ipynb)).\n",
    "\n",
    "When the orientation differences between the two images are large this approach will not yield a reasonable initial estimate for the registration.\n",
    "\n",
    "When working with clinical images, the DICOM tags define the orientation and position of the anatomy in the volume. The tags of interest are:\n",
    "<ul>\n",
    "  <li> (0020|0032) Image Position (Patient) : coordinates of the the first transmitted voxel. </li>\n",
    "  <li>(0020|0037) Image Orientation (Patient): directions of first row and column in 3D space. </li>\n",
    "  <li>(0018|5100) Patient Position: Patient placement on the table \n",
    "  <ul>\n",
    "  <li> Head First Prone (HFP)</li>\n",
    "  <li> Head First Supine (HFS)</li>\n",
    "  <li> Head First Decibitus Right (HFDR)</li>\n",
    "  <li> Head First Decibitus Left (HFDL)</li>\n",
    "  <li> Feet First Prone (FFP)</li>\n",
    "  <li> Feet First Supine (FFS)</li>\n",
    "  <li> Feet First Decibitus Right (FFDR)</li>\n",
    "  <li> Feet First Decibitus Left (FFDL)</li>\n",
    "  </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "The patient position is manually entered by the CT/MR operator and thus can be erroneous (HFP instead of FFP will result in a $180^o$ orientation error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from IPython.html.widgets import interact, fixed\n",
    "     #display some html output\n",
    "from IPython.display import display, HTML \n",
    "\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = 'Output'\n",
    "INPUT_DIR = 'Data'\n",
    "\n",
    "    #this notebook works best using ITK-SNAP as your viewer \n",
    "    #please proivde the full path to the application below\n",
    "%env SITK_SHOW_COMMAND /Applications/ITK-SNAP.app/Contents/MacOS/ITK-SNAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_transform_and_image(transform, fixed_image, moving_image, outputfile_prefix):\n",
    "    '''\n",
    "    Write the given transformation to file, resample the moving_image onto the fixed_images grid and save the\n",
    "    result to file.\n",
    "    \n",
    "    Args:\n",
    "        transform (SimpleITK Transform): transform that maps points from the fixed image coordinate system to the moving.\n",
    "        fixed_image (SimpleITK Image): resample onto the spatial grid defined by this image.\n",
    "        moving_image (SimpleITK Image): resample this image.\n",
    "        outputfile_prefix (string): transform is written to outputfile_prefix.tfm and resampled image is written to \n",
    "                                    outputfile_prefix.mhd.\n",
    "    '''\n",
    "                             \n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetReferenceImage(fixed_image)\n",
    "                #SimpleITK supports several interpolation options.     \n",
    "    resample.SetInterpolator(sitk.sitkLinear)  \n",
    "    resample.SetTransform(transform)\n",
    "    sitk.WriteImage(resample.Execute(moving_image), outputfile_prefix+'.mhd')\n",
    "    sitk.WriteTransform(transform, outputfile_prefix+'.tfm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "#callback invoked when the StartEvent happens, sets up our new data\n",
    "def start_plot():\n",
    "    global metric_values, multires_iterations \n",
    "    metric_values = []\n",
    "    multires_iterations = []\n",
    "\n",
    "#callback invoked when the EndEvent happens, do cleanup of data and figure\n",
    "def end_plot():\n",
    "    global metric_values, multires_iterations  \n",
    "    del metric_values\n",
    "    del multires_iterations\n",
    "          #close figure, we don't want to get a duplicate of the plot latter on\n",
    "    plt.close()\n",
    "\n",
    "#callback invoked when the IterationEvent happens, update our data and display new figure    \n",
    "def plot_value(registration_method, plot_title):\n",
    "    global metric_values, multires_iterations\n",
    "    metric_values.append(registration_method.GetMetricValue())\n",
    "         #clear the output area (wait=True, to reduce flickering), and plot current data\n",
    "    clear_output(wait=True)    \n",
    "    plt.plot(metric_values, 'r')\n",
    "    plt.plot(multires_iterations, [metric_values[index] for index in multires_iterations], 'b*')\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Iteration Number',fontsize=12)\n",
    "    plt.ylabel('Metric Value',fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "#callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the \n",
    "#metric_values list. We assume this event happens before the first IterationEvent on the next resolution.\n",
    "def update_multires_iterations():\n",
    "    global metric_values, multires_iterations\n",
    "    multires_iterations.append(len(metric_values))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_directory = os.path.join(INPUT_DIR,'CIRS057A')\n",
    "\n",
    "         #global variables 'selected_series_moving/fixed' are updated by the interact function\n",
    "selected_series_fixed = ''\n",
    "selected_series_moving = ''\n",
    "def DICOM_series_dropdown_callback(fixed_image, moving_image, series_dictionary):    \n",
    "    global selected_series_fixed\n",
    "    global selected_series_moving\n",
    "               #print some information about the series from the meta-data dictionary\n",
    "              #DICOM standard part 6, Data Dictionary: http://medical.nema.org/medical/dicom/current/output/pdf/part06.pdf\n",
    "    img_fixed = sitk.ReadImage(series_dictionary[fixed_image][0])\n",
    "    img_moving = sitk.ReadImage(series_dictionary[moving_image][0])\n",
    "          #there are many interesting tags in a DICOM format, print out some of them\n",
    "    tags_to_print = {'0010|0010': 'Patient name: ', \n",
    "                     '0008|0060' : 'Modality: ',\n",
    "                     '0020|0032' : 'Image Position (Patient): ',\n",
    "                     '0020|0037' : 'Image Orientation (Patient): ',\n",
    "                     '0018|5100' : 'Patient Position: '}\n",
    "    html_table = []\n",
    "    html_table.append('<table><tr><td><b>Tag</b></td><td><b>Fixed Image</b></td><td><b>Moving Image</b></td></tr>')\n",
    "    for tag in tags_to_print:\n",
    "        fixed_tag = ''\n",
    "        moving_tag = ''\n",
    "        try:            \n",
    "            fixed_tag = img_fixed.GetMetaData(tag)\n",
    "        except: #ignore if the tag isn't in the dictionary\n",
    "            pass\n",
    "        try:            \n",
    "            moving_tag = img_moving.GetMetaData(tag)\n",
    "        except: #ignore if the tag isn't in the dictionary\n",
    "            pass           \n",
    "        html_table.append('<tr><td>' + tags_to_print[tag] + \n",
    "                          '</td><td>' + fixed_tag + \n",
    "                          '</td><td>' + moving_tag + '</td></tr>')\n",
    "    html_table.append('</table>')\n",
    "    display(HTML(''.join(html_table)))\n",
    "    selected_series_fixed = fixed_image\n",
    "    selected_series_moving = moving_image\n",
    "\n",
    "             #directory contains multiple DICOM studies/series, store\n",
    "             #in dictionary with key being the seriesID\n",
    "reader = sitk.ImageSeriesReader()\n",
    "series_file_names = {}\n",
    "series_IDs = reader.GetGDCMSeriesIDs(data_directory)\n",
    "            #check that we have at least one series\n",
    "if series_IDs:\n",
    "    for series in series_IDs:\n",
    "        series_file_names[series] = reader.GetGDCMSeriesFileNames(data_directory, series)\n",
    "    \n",
    "    interact(DICOM_series_dropdown_callback, fixed_image=series_IDs, moving_image =series_IDs, series_dictionary=fixed(series_file_names)); \n",
    "else:\n",
    "    print('Data directory does not contain any DICOM series.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "         #continue only if the previous cell was run and the series were selected\n",
    "if 'selected_series_fixed' in globals() and 'selected_series_moving' in globals():\n",
    "    reader.SetFileNames(series_file_names[selected_series_fixed])\n",
    "    fixed_image = reader.Execute()\n",
    "    reader.SetFileNames(series_file_names[selected_series_moving])\n",
    "    original_moving_image = reader.Execute()\n",
    "          #look at our images and their alignment (the two instances of ITK-SNAP share a spatially linked cursor)\n",
    "    sitk.Show(fixed_image)\n",
    "    sitk.Show(original_moving_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def orientation_selection_dropdown_callback(orientation, image, orientations_dictionary):\n",
    "    global moving_image\n",
    "    \n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetReferenceImage(image)\n",
    "    resample.SetInterpolator(sitk.sitkLinear)\n",
    "    transform = sitk.Euler3DTransform()\n",
    "    transform.SetCenter(image.TransformContinuousIndexToPhysicalPoint([(index-1)/2.0 for index in image.GetSize()]))\n",
    "    transform.SetMatrix(orientations_dictionary[orientation])\n",
    "    resample.SetTransform(transform)\n",
    "    moving_image = resample.Execute(image)\n",
    "    \n",
    "possible_orientation_changes = {'x=0, z=90': (0,-1,0,1,0,0,0,0,1),\n",
    "                                'x=0, z=-90': (0,1,0,-1,0,0,0,0,1),\n",
    "                                'x=0, z=180': (-1,0,0,0,-1,0,0,0,1),\n",
    "                                'x=180, z=0': (1,0,0,0,-1,0,0,0,-1),\n",
    "                                'x=180, z=90': (0,-1,0,-1,0,0,0,0,-1),\n",
    "                                'x=180, z=-90': (0,1,0,1,0,0,0,0,-1),\n",
    "                                'x=180, z=180': (-1,0,0,0,1,0,0,0,-1)}    \n",
    "all_orientations = possible_orientation_changes.copy()\n",
    "all_orientations['x=0, z=0'] = (1,0,0,0,1,0,0,0,1)\n",
    "\n",
    "#moving_image = sitk.Image(original_moving_image)\n",
    "moving_image = None\n",
    "interact(orientation_selection_dropdown_callback, orientation=all_orientations.keys(), image=fixed(original_moving_image), orientations_dictionary=fixed(all_orientations)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sitk.Show(moving_image, title='Moving Image')\n",
    "sitk.Show(original_moving_image, title= 'Original Moving Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multires_registration(fixed_image, moving_image, initial_transform, output_prefix):\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100, estimateLearningRate=registration_method.Once)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift() \n",
    "    registration_method.SetInitialTransform(initial_transform)\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors = [4,2,1])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas = [2,1,0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    registration_method.RemoveAllCommands()\n",
    "    registration_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "    registration_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "    registration_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, update_multires_iterations) \n",
    "    registration_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_value(registration_method, 'Multi Scale'))\n",
    "\n",
    "    final_transform = registration_method.Execute(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
    "                                                  sitk.Cast(moving_image, sitk.sitkFloat32))\n",
    "\n",
    "    save_transform_and_image(final_transform, fixed_image, moving_image, os.path.join(OUTPUT_DIR, output_prefix))\n",
    "    sitk.Show(fixed_image)\n",
    "    sitk.Show(sitk.ReadImage(os.path.join(OUTPUT_DIR, output_prefix + '.mhd')))\n",
    "    print('Final metric value: {0}'.format(registration_method.GetMetricValue()))\n",
    "    print('Optimizer\\'s stopping condition, {0}'.format(registration_method.GetOptimizerStopConditionDescription()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize as usual (assumes orientation is similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        #initialize\n",
    "initial_transform = sitk.CenteredTransformInitializer(sitk.Cast(fixed_image,moving_image.GetPixelIDValue()), \n",
    "                                                      moving_image, \n",
    "                                                      sitk.Euler3DTransform(), \n",
    "                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "     #register\n",
    "multires_registration(fixed_image, moving_image, initial_transform, 'final-standardInitialization')                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Iinitialize using all orientations\n",
    "\n",
    "As we want to account for significant orientation differences due to erroneous patient position (HFS...) we evaluate the similarity measure at eight locations corresponding to the various orientation differences. This can be done in two ways which will be illustrated below:\n",
    "<ul>\n",
    "<li>Use the ImageRegistrationMethod.MetricEvaluate() method.</li>\n",
    "<li>Use the Exhaustive optimizer.\n",
    "</ul>\n",
    "\n",
    "The former approach is more computationally intensive as it constructs and configures a metric object each time it is invoked. It is therefore more appropriate for use if the set of parameter values we want to evaluate are not on a rectilinear grid in the parameter space. The latter approach is appropriate if the set of parameter values are on a rectilinear grid, in which case the approach is more computationally efficient.\n",
    "\n",
    "In both cases we use the CenteredTransformInitializer to obtain the initial translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MetricEvaluate\n",
    "\n",
    "To use the MetricEvaluate method we create a ImageRegistrationMethod, set its metric and interpolator. We then iterate over all parameter settings, set the initial transform and evaluate the metric. The minimal similarity measure value corresponds to the best paramter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r1 -n1\n",
    "#the magic above will time a single run of this cell\n",
    "\n",
    "initial_transform = sitk.Euler3DTransform(sitk.CenteredTransformInitializer(sitk.Cast(fixed_image,moving_image.GetPixelIDValue()), \n",
    "                                                                            moving_image, \n",
    "                                                                            sitk.Euler3DTransform(), \n",
    "                                                                            sitk.CenteredTransformInitializerFilter.GEOMETRY))\n",
    "            #registration framework setup\n",
    "registration_method = sitk.ImageRegistrationMethod()\n",
    "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "registration_method.SetMetricSamplingPercentage(0.01)\n",
    "registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "        #evaluate the similarity metric using the eight possible orientations, translation is the same for all\n",
    "registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "best_orientation = (1,0,0,0,1,0,0,0,1)\n",
    "best_similarity_value = registration_method.MetricEvaluate(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
    "                                                           sitk.Cast(moving_image, sitk.sitkFloat32))    \n",
    "       #iterate over all other rotation parameter settings \n",
    "for key, orientation in possible_orientation_changes.items():\n",
    "    initial_transform.SetMatrix(orientation)\n",
    "    registration_method.SetInitialTransform(initial_transform)\n",
    "    current_similarity_value = registration_method.MetricEvaluate(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
    "                                                                  sitk.Cast(moving_image, sitk.sitkFloat32))\n",
    "    if current_similarity_value < best_similarity_value:\n",
    "        best_similarity_value = current_similarity_value\n",
    "        best_orientation = orientation\n",
    "\n",
    "initial_transform.SetMatrix(best_orientation)\n",
    "\n",
    "      #register\n",
    "multires_registration(fixed_image, moving_image, initial_transform, 'final-robustInitializationMetricEvaluate')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive optimizer\n",
    "\n",
    "The exhaustive optimizer evaluates the similarity measure using a grid overlaid on the parameter space.\n",
    "The grid is centered on the parameter values set by the SetInitialTransform, and the location of its vertices are determined by the <b>numberOfSteps</b>, <b>stepLength</b> and <b>optimizer scales</b>. To quote the documentation of this class: \"a side of the region is stepLength*(2*numberOfSteps[d]+1)*scaling[d].\"\n",
    "\n",
    "Using this approach we have superfluous evaluations (15 evaluations corresponding to 3 values for rotations around the x axis and five for rotation around the z axis, as compared to the 8 evaluations using the MetricEvaluate method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r1 -n1\n",
    "#the magic above will time a single run of this cell\n",
    "\n",
    "initial_transform = sitk.CenteredTransformInitializer(sitk.Cast(fixed_image,moving_image.GetPixelIDValue()), \n",
    "                                                      moving_image, \n",
    "                                                      sitk.Euler3DTransform(), \n",
    "                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "registration_method = sitk.ImageRegistrationMethod()\n",
    "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "registration_method.SetMetricSamplingPercentage(0.01)\n",
    "registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "    #the order of parameters for the Euler3DTransform is [angle_x, angle_y, angle_z, t_x, t_y, t_z]\n",
    "registration_method.SetOptimizerAsExhaustive(numberOfSteps=[1,0,2,0,0,0], stepLength = np.pi)\n",
    "registration_method.SetOptimizerScales([1,1,0.5,1,1,1])\n",
    "    #do the registration in-place so that the initial_transform is modified\n",
    "registration_method.SetInitialTransform(initial_transform)\n",
    "registration_method.Execute(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
    "                            sitk.Cast(moving_image, sitk.sitkFloat32))\n",
    "\n",
    "multires_registration(fixed_image, moving_image, initial_transform, 'final-robustInitialization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
